{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDb Prediction Analysis\n",
    "## Post-Neural-Network Training...\n",
    "Now that the multi-layer preceptron deep learning model has finished training and producing results from 3 separate training sets, I will conduct some analysis to evaluate how well the model performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle as pkl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory structure\n",
    "parent_path = '/Users/cheng-haotai/Documents/Projects_Data/IMDb_Predictor/'\n",
    "prediction_folder = 'prediction_results/'\n",
    "prediction_path = parent_path + prediction_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Prediction Results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of original prediction results\n",
    "pred_ext = '.csv'\n",
    "print 'Names of movie prediction files:'\n",
    "pred_files = []\n",
    "for filename in os.listdir(prediction_path):\n",
    "    if filename.endswith(pred_ext):\n",
    "        pred_files.append(prediction_path + filename)\n",
    "        print prediction_path + filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of cleaned prediction results\n",
    "formatted_files = []\n",
    "for name in pred_files:\n",
    "    name = name.replace('movie_prediction', 'formatted')\n",
    "    formatted_files.append(name)\n",
    "    print name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up prediction files (2nd column values have list of lists brackets)\n",
    "for idx, name in enumerate(pred_files):\n",
    "    new_data = []\n",
    "    with open(name, 'r') as csvread:\n",
    "        csv_read = csv.reader(csvread)\n",
    "        for row in csv_read:\n",
    "            row[2] = row[2].replace('[', '')\n",
    "            row[2] = row[2].replace(']', '')\n",
    "            new_data.append(row)\n",
    "    with open(formatted_files[idx], 'w') as csvwrite:\n",
    "        csv_write = csv.writer(csvwrite)\n",
    "        csv_write.writerows(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing into Pandas...\n",
    "The CSV files containing movie predictions of the test set (using 3 separate training sets to train the regression model). Now, I will be constructing pandas dataframes of the three test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = prediction_path + 'test_index.pickle'\n",
    "with open(test_idx, 'rb') as pickle_open:\n",
    "    test_info = pkl.load(pickle_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use test indexes to load metadata for the movies in the test set\n",
    "metadata_path = parent_path + 'movie_metadata_debug.csv'\n",
    "metadata_list = []\n",
    "metadata_header = []\n",
    "with open(metadata_path, 'r') as metadata_read:\n",
    "    metadata_parsed = csv.reader(metadata_read)\n",
    "    for idx, row in enumerate(metadata_parsed):\n",
    "        if idx == 0:\n",
    "            metadata_header = row\n",
    "        if (idx - 1) in test_info:\n",
    "            metadata_list.append(row)\n",
    "df_meta = pd.DataFrame(metadata_list, columns = metadata_header)\n",
    "# df_meta.columns = df_meta.iloc[0]\n",
    "# df_meta = df_meta[1:]\n",
    "# df_meta = df_meta.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info about metadata dataframe\n",
    "print 'Shape of metadata dataframe:', df_meta.shape\n",
    "print 'Columns of metadata dataframe:\\n', df_meta.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each prediction file, load the data into a pandas dataframe\n",
    "pred_df_list = []\n",
    "for name in formatted_files:\n",
    "    pred_df_list.append(pd.read_csv(name, index_col=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_list[0].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta.loc[0]['imdb_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_list[2].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_whole = pd.read_csv(metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_whole.loc[df_whole['imdb_score'] == 5.8]\n",
    "df_whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
